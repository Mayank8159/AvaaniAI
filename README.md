<div align="center">

<img src="https://capsule-render.vercel.app/render?type=wave&color=gradient&height=250&section=header&text=PROJECT%20AVANI&fontSize=80&animation=twinkling&fontAlignY=38&desc=UEMK%20Neural%20Shell%20v1.0.4&descAlignY=60&descSize=20" width="100%" />

<br/>

<a href="https://git.io/typing-svg">
  <img src="https://readme-typing-svg.demolab.com?font=Orbitron&weight=900&size=50&pause=1000&color=38B2AC&center=true&vCenter=true&width=900&height=100&lines=AVANI+NEURAL+INTERFACE;THE+SILICON+SOUL;UEM+KOLKATA+RESEARCH" alt="Typing SVG" />
</a>

<a href="https://git.io/typing-svg">
  <img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=600&size=22&pause=1000&color=00FF41&center=true&vCenter=true&width=600&lines=SYSTEM+STATUS:+ONLINE;NEURAL+LINK:+ACTIVE;VRM+RENDERER:+READY;TARGET:+HUMANOID+v1" alt="Typing SVG" />
</a>

<p>
  <img src="https://img.shields.io/badge/Next.js-15-black?style=for-the-badge&logo=next.js&logoColor=white" />
  <img src="https://img.shields.io/badge/Three.js-WebGL-blueviolet?style=for-the-badge&logo=three.js" />
  <img src="https://img.shields.io/badge/UI-VisionOS-38B2AC?style=for-the-badge" />
  <img src="https://img.shields.io/badge/STATUS-OPERATIONAL-orange?style=for-the-badge" />
</p>

<br/><br/>

> â **The line between silicon and soul is thinning.** We don't just chat; we re-engineer human-AI interaction into a high-fidelity emotional loop. â

</div>

---

## âš¡ System Architecture

<table>
  <tr>
    <td width="60%">
      <h3 align="left">The Neural Pipeline</h3>
      The shell operates on a <b>Priority-Driven</b> render loop:
      <br/><br/>
      1. <b>Ingest:</b> Captures <code>LiveContext</code> via WebSocket binary streams.
      <br/>
      2. <b>Process:</b> Maps tracking data to <code>VRMHumanBoneName</code> nodes.
      <br/>
      3. <b>Idle Logic:</b> Overlays procedural breathing and micro-saccades.
      <br/>
      4. <b>Override:</b> Executes the <b>Wave Protocol</b> for instant greeting.
    </td>
    <td width="40%">
      <div align="center">
        <pre>
     [Voice/Live]
        â¬‡
  +------------+
  |  CONTEXT   | ğŸ“¡ WS
  +------------+
        â¬‡
  +------------+
  | CONTROLLER | ğŸ­ Pose
  +------------+
        â¬‡
  +------------+
  |   RENDER   | ğŸ’ GL
  +------------+
        â¬‡
     [AVANI_UI]
        </pre>
      </div>
    </td>
  </tr>
</table>

---

## ğŸ•¹ï¸ Neural Shell Modules

| Module | Status | Technology | Function |
| :--- | :---: | :--- | :--- |
| **`app/`** | ğŸŸ¢ | **Next.js 15** | VisionOS Glassmorphic UI & Voice Dock. |
| **`features/`** | ğŸŸ¢ | **Pixiv VRM** | Humanoid bone controllers and emotion drivers. |
| **`live/`** | ğŸŸ¡ | **WebSockets** | Real-time neural link for head tracking. |
| **`physics/`** | ğŸŸ¢ | **SpringBone** | Cloth and hair physics simulation. |

---

## ğŸš€ Deployment Protocol

<div align="center">

<a href="https://git.io/typing-svg">
  <img src="https://readme-typing-svg.demolab.com?font=Console&size=20&pause=1000&color=FFFFFF&background=000000&center=true&vCenter=true&width=600&height=100&lines=git+clone+avani-ai;npm+install;npm+run+dev;>_ SYSTEM+LAUNCHED" alt="Terminal Typing" />
</a>

</div>

```bash
# Clone the repository
git clone [https://github.com/Team7SENSITIVE/avani-ai.git](https://github.com/Team7SENSITIVE/avani-ai.git)

# Initialize Neural Shell
npm install
npm run dev

```

---

## ğŸ§  Animation Priority Pipeline

To prevent "bone-locking" glitches, the render loop follows a specific execution hierarchy:

1. **Pose Initialization** (Base T-Pose)
2. **Live Tracking** (Eye/Face data from WebSockets)
3. **Procedural Idle** (Breathing & Swaying)
4. **Global Overrides** (The Wave Protocol) â¬…ï¸ **[HIGHEST PRIORITY]**
5. **SpringBone Physics** (Hair & Clothing)

---

<div align="center">

### ğŸ›¡ï¸ TEAM 7SENSITIVE ğŸ›¡ï¸

**DEVELOPED BY**
**[ Shreyan Mitra ] â€¢ [ Mayank Kumar Sharma ] â€¢ [ Priyanshu Roy ]**

**PROUD STUDENTS OF UEM KOLKATA**
*Pushing the boundaries of Neural Systems*

</div>
